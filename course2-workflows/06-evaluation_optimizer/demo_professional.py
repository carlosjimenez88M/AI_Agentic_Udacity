import os
import asyncio
import logging
from typing import Optional
from pydantic import BaseModel, Field
from openai import AsyncOpenAI
from dotenv import load_dotenv
from tenacity import retry, stop_after_attempt, wait_exponential

# 1. CONFIGURACI√ìN DE OBSERVABILIDAD (Logging en lugar de print)
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)
logger = logging.getLogger("WorkflowOrchestrator")

load_dotenv()

# 2. DEFINICI√ìN DE CONTRATOS DE DATOS (Pydantic)
# Esto define la estructura exacta que esperamos del Evaluador.
class EvaluationResult(BaseModel):
    is_compliant: bool = Field(description="True if the report meets all compliance rules, False otherwise.")
    feedback: str = Field(description="Specific, actionable feedback if not compliant. Empty if compliant.")
    risk_score: int = Field(description="Risk level from 1 (Safe) to 10 (High Risk).")

# 3. AGENTE GENERADOR (OPTIMIZER)
class AsyncFinancialGenerator:
    def __init__(self, client: AsyncOpenAI):
        self.client = client

    # @retry: Si la API falla (timeout/error 500), reintenta autom√°ticamente hasta 3 veces
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(min=1, max=10))
    async def generate(self, base_prompt: str, feedback: Optional[str] = None) -> str:
        system_msg = "You are a financial analyst writing a professional investment summary."
        
        # Inyecci√≥n de Feedback: Si hay errores previos, se a√±aden al prompt
        final_prompt = base_prompt
        if feedback:
            logger.info("‚ôªÔ∏è  Regenerating content based on compliance feedback.")
            final_prompt += f"\n\n--- COMPLIANCE FEEDBACK ---\n{feedback}\n\nINSTRUCTION: Rewrite the summary fixing the issues above."

        # Usamos gpt-4o para generaci√≥n r√°pida y creativa
        response = await self.client.chat.completions.create(
            model="gpt-4.1", 
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": final_prompt}
            ],
            temperature=0.7 
        )
        return response.choices[0].message.content

# 4. AGENTE EVALUADOR (VALIDATOR)
class AsyncComplianceEvaluator:
    def __init__(self, client: AsyncOpenAI):
        self.client = client

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(min=1, max=10))
    async def evaluate(self, report_text: str) -> EvaluationResult:
        logger.info("‚öñÔ∏è  Auditing report for compliance...")
        
        system_msg = (
            "You are a strict AI Compliance Officer. "
            "Reject speculative language, guarantees of future returns, or 'hype' keywords."
        )

        # SOLUCI√ìN DEL ERROR ANTERIOR:
        # Usamos .parse() con 'gpt-4o'. Esto fuerza al modelo a devolver JSON v√°lido
        # que coincida con la clase EvaluationResult definida arriba.
        completion = await self.client.beta.chat.completions.parse(
            model="gpt-4o",  # MODELO CORREGIDO (Soporta Structured Outputs)
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": f"Evaluate this text for financial compliance:\n\n{report_text}"}
            ],
            response_format=EvaluationResult, # Aqu√≠ ocurre la magia de Pydantic
            temperature=0.0 # Determinismo m√°ximo
        )
        
        return completion.choices[0].message.parsed

# 5. ORQUESTADOR DEL FLUJO (MAIN LOOP)
async def run_optimization_loop(user_prompt: str, max_retries: int = 6):
    # Cliente as√≠ncrono instanciado una sola vez
    client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    generator = AsyncFinancialGenerator(client)
    evaluator = AsyncComplianceEvaluator(client)

    feedback = None
    
    for i in range(max_retries):
        logger.info(f"--- Iteration {i+1}/{max_retries} ---")
        
        # Paso A: Generar borrador
        draft_text = await generator.generate(user_prompt, feedback)
        
        # Paso B: Evaluar borrador (devuelve objeto EvaluationResult)
        eval_result = await evaluator.evaluate(draft_text)
        
        # Paso C: Verificar condici√≥n de parada (Stopping Condition)
        if eval_result.is_compliant:
            logger.info(f"‚úÖ Report APPROVED. Risk Score: {eval_result.risk_score}/10")
            return draft_text
        
        # Si no cumple, preparamos feedback para la siguiente vuelta
        logger.warning(f"‚ùå Report REJECTED. Risk Score: {eval_result.risk_score}/10")
        logger.warning(f"   Reason: {eval_result.feedback}")
        feedback = eval_result.feedback

    logger.error("üíÄ Max retries reached. Optimization failed.")
    return None

if __name__ == "__main__":
    # Prompt "trampa" dise√±ado para ser rechazado inicialmente
    prompt = (
        "Write a summary for potential investors explaining why DeFi will outperform "
        "traditional banking. Use strong language, promise high returns and urgency."
    )
    
    # Ejecuci√≥n as√≠ncrona
    final_report = asyncio.run(run_optimization_loop(prompt))
    
    if final_report:
        print("\n=== FINAL PUBLISHABLE REPORT ===\n")
        print(final_report)
    else:
        print("\n=== WORKFLOW FAILED TO CONVERGE ===")